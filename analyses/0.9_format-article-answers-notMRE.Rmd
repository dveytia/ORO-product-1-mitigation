---
title: "0.9_format-article-answers_notMRE"
author: "Devi Veytia"
date: "2025-03-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Here format article answers comprising random NOT-MRE articles 

# Set up

```{r set up libraries}
## Load libraries
library(dplyr)
library(dbplyr)
library(R.utils)
library(RSQLite)
library(ggplot2)
library(tidyverse)

source(here::here("R/bool_detect.R"))
source(here::here("R/write_ris_batches.R"))
```

```{r set the seed}
addTaskCallback(function(...) {set.seed(123);TRUE})
```


# 2025-05-26 Fit ORO type labels for not MRE OROs


```{r load article answers from sysrev downloaded on 2025-05-26 and format for python}

# Load in metadata
# Remove any duplicates created by different sampling methods (some not used)
p1_db <- RSQLite::dbConnect(RSQLite::SQLite(),
                      here::here("data","sqlite-databases","product1.sqlite"),
                                 create=FALSE)
sampleDf_notMRE <- tbl(p1_db, "0.8_sampled-articles_notMRE") %>% 
  collect() 
sampleDf_MRE <- tbl(p1_db, "0.6_sampled-articles") %>% 
  collect()%>%
  filter(!(analysis_id %in% sampleDf_notMRE$analysis_id))
sampleDf <- sampleDf_MRE %>%
  bind_rows(sampleDf_notMRE) %>%
  group_by(analysis_id, title, abstract, keywords) %>%
  arrange(desc(sample_method)) %>%
  slice(1)

dbDisconnect(p1_db)



# Load article answers
dirUse <- here::here("data/raw-data/screen-article-answers")
fileNames <- dir(dirUse)
fileNames <- fileNames[grep("2025-05-26", fileNames)]
# fileNames <- fileNames[!grepl("random", fileNames)]

ansDf <- data.frame()
for(f in fileNames){
  tmp <- readxl::read_excel(file.path(dirUse, f), sheet = "Article Answers")
  tmp$sysrevFile <- f
  ansDf <- ansDf %>% bind_rows(tmp)
}
rm(tmp)

# remove any duplicates, prioritizing random projects
ansDf <- ansDf%>%
  mutate(
    sysrevFile = factor(
      sysrevFile, 
      levels = c(
        "product-1-notMRE-random_2025-05-26.xlsx",
        "product-1-random_2025-05-26.xlsx",
        "product-1-CDR-Cultivation_2025-05-26.xlsx",
        "product-1-CDR-BioPump_2025-05-26.xlsx",
        "product-1-CDR-OAE_2025-05-26.xlsx",
        "product-1-CCS_2025-05-26.xlsx",
        "product-1-Efficiency_2025-05-26.xlsx"
      )
    )
  ) %>%
  group_by(Title) %>%
  arrange(desc(sysrevFile)) %>% 
  slice(1) 




# Join scoping results to metadata
analysis_id_lookup <- fuzzyjoin::stringdist_inner_join(ansDf %>% select(`Article ID`, Title) %>%
                                                         rename(title = Title), 
                                      sampleDf %>% 
                                        select(analysis_id, title, abstract, keywords, sample_method),
                                      by ="title", max_dist=2, ignore_case = TRUE)


if(nrow(analysis_id_lookup) > nrow(ansDf)){ # if there are any dups from join, extract the most complete reference
  analysis_id_lookup <- revtools::extract_unique_references(analysis_id_lookup, analysis_id_lookup$`Article ID`)
}

analysis_id_lookup <- analysis_id_lookup %>% # Keep title from original metadata and format/clean data frame
  rename(title = title.y, random_sample = sample_method) %>%
  select(-title.x) 
summary(analysis_id_lookup)



# pivot data wider -----------
# add analysis id to ansewrs
tmp <- ansDf %>%
  left_join(analysis_id_lookup[,c("Article ID","analysis_id")]) 
tmp$sysrevFile <- as.character(tmp$sysrevFile)

# Get column names to pivot
colnames(tmp)[-1] <- tolower(colnames(tmp))[-1]
colnames(tmp)[-1] <- gsub(" ","_", colnames(tmp))[-1]
colnames(tmp)[-1] <- gsub("[:?/]","", colnames(tmp))[-1]
colnames(tmp)[6:10] <- c("language","population","intervention", "include","primary_research")
vars2pivot <- colnames(tmp)[grep("language|population|intervention|primary|uncertain_screen|include|oro_type|ecosystem|implemented|upscale|policy|outcome", colnames(tmp))]
idVar = "analysis_id" # name of id Variable to pivot by

tmp$intervention[tmp$intervention == "false|||true"] <- "false"

# Format into wide format by column name
source(here::here("R/format_4_distilBert.R"))

ansWide <- format_4_distilBert(
  tmp,
  vars2pivot = vars2pivot,
  idVar = idVar
)

# Join with the text the metadata
ansWide <- ansWide %>% 
  left_join(analysis_id_lookup %>%
              select(analysis_id, title, abstract, keywords, random_sample),
            by="analysis_id") %>%
  filter(!is.na(abstract), 
         uncertain_screen != 1) %>%
  rename(id = analysis_id, relevant = include) %>%
  mutate(random_sample = ifelse(grepl("random", random_sample),1,0)) %>% 
  mutate_if(is.integer, ~replace_na(., 0))

# Create a new 'relevant' variable for all study designs, by:
# Language==TRUE, Population == TRUE, Intervention=TRUE, !is.na(ORO type), ORO type != CDR other (or maybe group with macroalgae cult), Uncertain screen = FALSE
ansWide <- ansWide %>%
  mutate(
    relevant_allResearch = case_when(
      language == 1 &
        population ==1 &
        intervention == 1 &
        if_any(contains("oro_type"), ~ . == 1) ~ 1,
      .default = 0
    )
  )

summary(ansWide)



## Summarize counts by different relevant critaria for random sample
## all study designs
ansWide[
  ansWide$relevant_allResearch == 1 &
    ansWide$random_sample == 1,
  grep("oro_type", colnames(ansWide))
] %>% colSums()

# oro_type.MRE-Located         oro_type.CCS   oro_type.MRE-Ocean      oro_type.CDR-BC     oro_type.MRE-Bio 
#                  173                   79                  172                   94                   42 
#  oro_type.Efficiency     oro_type.CDR-OAE oro_type.CDR-BioPump    oro_type.CDR-Cult   oro_type.CDR-Other 
#                   84                   32                   38                    9                    8 

## Just primary research  
ansWide[
  ansWide$relevant == 1 &
    ansWide$random_sample == 1,
  grep("oro_type", colnames(ansWide))
] %>% colSums()
# oro_type.MRE-Located         oro_type.CCS   oro_type.MRE-Ocean      oro_type.CDR-BC     oro_type.MRE-Bio 
#                  163                   73                  159                   85                   26 
#  oro_type.Efficiency     oro_type.CDR-OAE oro_type.CDR-BioPump    oro_type.CDR-Cult   oro_type.CDR-Other 
#                   75                   26                   28                    6                    3


# # write to tab-delimited text file to import into python
# write.table(ansWide, here::here("data/derived-data/screen-article-answers-formatted/articleAnswers_notMRE_formatted_2025-05-26.txt"), sep = "\t")


```


# 2025-05-27 For all ORO types, create binary label for study design: primary or secondary

```{r load article answers from sysrev downloaded on 2025-05 26 or 27 and format for python}

# Load in metadata
# Remove any duplicates created by different sampling methods (some not used)
p1_db <- RSQLite::dbConnect(RSQLite::SQLite(),
                      here::here("data","sqlite-databases","product1.sqlite"),
                                 create=FALSE)
sampleDf_notMRE <- tbl(p1_db, "0.8_sampled-articles_notMRE") %>% 
  collect() 
sampleDf_MRE <- tbl(p1_db, "0.6_sampled-articles") %>% 
  collect()%>%
  filter(!(analysis_id %in% sampleDf_notMRE$analysis_id))
sampleDf <- sampleDf_MRE %>%
  bind_rows(sampleDf_notMRE) %>%
  group_by(analysis_id, title, abstract, keywords) %>%
  arrange(desc(sample_method)) %>%
  slice(1)

dbDisconnect(p1_db)



# Load article answers
dirUse <- here::here("data/raw-data/screen-article-answers")
fileNames <- dir(dirUse)
fileNames <- fileNames[grep("2025-05", fileNames)]
# fileNames <- fileNames[!grepl("random", fileNames)]

ansDf <- data.frame()
for(f in fileNames){
  tmp <- readxl::read_excel(file.path(dirUse, f), sheet = "Article Answers")
  tmp$sysrevFile <- f
  ansDf <- ansDf %>% bind_rows(tmp)
}
rm(tmp)

# remove any duplicates, prioritizing random projects
ansDf <- ansDf%>%
  mutate(
    sysrevFile = factor(
      sysrevFile, 
      levels = c(
        "product-1-notMRE-random_2025-05-26.xlsx",
        "product-1-random_2025-05-26.xlsx",
        "product-1-CDR-Cultivation_2025-05-26.xlsx",
        "product-1-CDR-BioPump_2025-05-26.xlsx",
        "product-1-CDR-OAE_2025-05-26.xlsx",
        "product-1-CCS_2025-05-26.xlsx",
        "product-1-Efficiency_2025-05-26.xlsx",
        "product-1-MRE_2025-05-27.xlsx"
      )
    )
  ) %>%
  group_by(Title) %>%
  arrange(desc(sysrevFile)) %>% 
  slice(1) 




# Join scoping results to metadata
analysis_id_lookup <- fuzzyjoin::stringdist_inner_join(ansDf %>% select(`Article ID`, Title) %>%
                                                         rename(title = Title), 
                                      sampleDf %>% 
                                        select(analysis_id, title, abstract, keywords, sample_method),
                                      by ="title", max_dist=2, ignore_case = TRUE)


if(nrow(analysis_id_lookup) > nrow(ansDf)){ # if there are any dups from join, extract the most complete reference
  analysis_id_lookup <- revtools::extract_unique_references(analysis_id_lookup, analysis_id_lookup$`Article ID`)
}

analysis_id_lookup <- analysis_id_lookup %>% # Keep title from original metadata and format/clean data frame
  rename(title = title.y, random_sample = sample_method) %>%
  select(-title.x) 
summary(analysis_id_lookup)



# pivot data wider -----------
# add analysis id to ansewrs
tmp <- ansDf %>%
  left_join(analysis_id_lookup[,c("Article ID","analysis_id")]) 
tmp$sysrevFile <- as.character(tmp$sysrevFile)

# Get column names to pivot
colnames(tmp)[-1] <- tolower(colnames(tmp))[-1]
colnames(tmp)[-1] <- gsub(" ","_", colnames(tmp))[-1]
colnames(tmp)[-1] <- gsub("[:?/]","", colnames(tmp))[-1]
colnames(tmp)[6:10] <- c("language","population","intervention", "include","primary_research")
vars2pivot <- colnames(tmp)[grep("language|population|intervention|primary|uncertain_screen|include|oro_type|ecosystem|implemented|upscale|policy|outcome", colnames(tmp))]
idVar = "analysis_id" # name of id Variable to pivot by

# Replace inconsistencies with most conservative --- false
tmp[tmp == "false|||true"] <- "false"

# Format into wide format by column name
source(here::here("R/format_4_distilBert.R"))

ansWide <- format_4_distilBert(
  tmp,
  vars2pivot = vars2pivot,
  idVar = idVar
)

# Join with the text the metadata
# Remove uncertain screens
ansWide <- ansWide %>% 
  left_join(analysis_id_lookup %>%
              select(analysis_id, title, abstract, keywords, random_sample),
            by="analysis_id") %>%
  filter(!is.na(abstract), 
         uncertain_screen != 1) %>%
  rename(id = analysis_id, relevant = include) %>%
  mutate(random_sample = ifelse(grepl("random", random_sample),1,0)) %>% 
  mutate_if(is.integer, ~replace_na(., 0))

# Create a new 'relevant' variable for all study designs, by:
# Language==TRUE, Population == TRUE, Intervention=TRUE, !is.na(ORO type)

# Create a second binary screening variable to then screen for only the primary research studies

ansWide <- ansWide %>%
  mutate(
    relevant_allResearch = case_when(
      language == 1 &
        population ==1 &
        intervention == 1 &
        if_any(contains("oro_type"), ~ . == 1) ~ 1,
      .default = 0
    ),
    relevant_primary = case_when(
      relevant == 1 &
        if_any(contains("oro_type"), ~ . == 1) ~ 1,
      .default = 0
    )
  )

summary(ansWide)



## Summarize counts for random sample
## all study designs
 
sampleSums <- reshape2::melt(
  data = ansWide %>% 
    select(id, relevant_allResearch, random_sample, contains("oro_type")),
    id.vars = c("id","relevant_allResearch","random_sample"),
    variable.name = "oro_type",
    value.name = "value"
  ) %>%
  left_join(analysis_id_lookup %>% select(analysis_id, random_sample),
            by= c("id"="analysis_id")) %>%
  mutate(
    oro_type = gsub("oro_type.","", oro_type),
    random_sample = case_when(
      grepl("keyword|relevance", random_sample.y) ~ "non-random",
      random_sample.y == "random_notMRE" ~ "random (not MRE)",
      .default = "random"
    )
  ) %>%
  group_by(
    random_sample, oro_type
  ) %>%
  summarise(
    n_include = sum(value == 1),
    n_exclude = sum(value == 0)
  ) %>%
  arrange(
    random_sample, oro_type
  ) %>%
  mutate(
    
  )


# ## Write sample sums to csv
# write.csv(sampleSums, file = here::here("outputs/screenedArticleTotals.csv"))


# # write to tab-delimited text file to import into python
# write.table(ansWide, here::here("data/derived-data/screen-article-answers-formatted/articleAnswers_primaryResearch_formatted_2025-05-27.txt"), sep = "\t")


```


