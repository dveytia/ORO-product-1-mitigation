=======================TASK PROLOG================================
Job 7536623 submitted on cluster spiritx from spiritx1.ipsl.fr
Job 7536623 submitted by dveytia with account lmd
Job 7536623 is running with 1 nodes and 39 cores on spiritx64-2
Job 7536623 memory requirements are 153600 MB per node
Job 7536623 starting at 2025/07/06 08:33:40
==================================================================
#!/bin/ksh -vx
#SBATCH --verbose
#SBATCH --output="%x.out_%j"
#SBATCH --nodes=1
#SBATCH --ntasks=15
#SBATCH --mem=150GB
#SBATCH --time=72:00:00
### on rentre dans le repertoire de run


cd /home/dveytia/IPython_Notebooks/Product_1/analyses/11_binary_ecosystem

+ cd /home/dveytia/IPython_Notebooks/Product_1/analyses/11_binary_ecosystem
mpiexec -n 5 python 11_binary_ecosystem_prediction.py+ mpiexec -n 5 python 11_binary_ecosystem_prediction.py
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
2025-07-06 08:33:44.343866: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-06 08:33:44.343863: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-06 08:33:44.343851: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-06 08:33:44.343865: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-06 08:33:44.343845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-06 08:33:45.798373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-06 08:33:45.798370: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-06 08:33:45.798467: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-06 08:33:45.798461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-06 08:33:45.798543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Dataset has been re-formatted and is ready
Dataset has been re-formatted and is ready
Dataset has been re-formatted and is ready
Dataset has been re-formatted and is ready
Dataset has been re-formatted and is ready
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1, 'F1': 0.8785172732541153}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1, 'F1': 0.8785172732541153}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1, 'F1': 0.8785172732541153}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1, 'F1': 0.8785172732541153}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1, 'F1': 0.8785172732541153}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': -1}
training bert with these params
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': None}
training bert with these params
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': None}
/home/dveytia/.local/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
11_binary_ecosystem_prediction.py:64: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.
  unseen_df2 = pd.read_csv(f'{dataFolder}/data/unique_references_UPDATE_13-05-2025.txt', delimiter='\t')
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-06 08:40:09.663983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [948]
	 [[{{node Placeholder/_2}}]]
2025-07-06 08:40:09.664294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [948]
	 [[{{node Placeholder/_2}}]]
Epoch 1/4
/home/dveytia/.local/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
11_binary_ecosystem_prediction.py:64: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.
  unseen_df2 = pd.read_csv(f'{dataFolder}/data/unique_references_UPDATE_13-05-2025.txt', delimiter='\t')
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-06 08:40:11.022532: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32 and shape [948,512]
	 [[{{node Placeholder/_0}}]]
2025-07-06 08:40:11.022842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [948,512]
	 [[{{node Placeholder/_1}}]]
Epoch 1/4
training bert with these params
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': None}
/home/dveytia/.local/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
11_binary_ecosystem_prediction.py:64: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.
  unseen_df2 = pd.read_csv(f'{dataFolder}/data/unique_references_UPDATE_13-05-2025.txt', delimiter='\t')
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-06 08:40:14.990683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [948,512]
	 [[{{node Placeholder/_1}}]]
2025-07-06 08:40:14.991004: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [948,512]
	 [[{{node Placeholder/_1}}]]
Epoch 1/4
training bert with these params
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': None}
training bert with these params
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': None}
/home/dveytia/.local/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
11_binary_ecosystem_prediction.py:64: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.
  unseen_df2 = pd.read_csv(f'{dataFolder}/data/unique_references_UPDATE_13-05-2025.txt', delimiter='\t')
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-06 08:40:16.859404: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [948]
	 [[{{node Placeholder/_2}}]]
2025-07-06 08:40:16.859729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32 and shape [948,512]
	 [[{{node Placeholder/_0}}]]
Epoch 1/4
/home/dveytia/.local/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
11_binary_ecosystem_prediction.py:64: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.
  unseen_df2 = pd.read_csv(f'{dataFolder}/data/unique_references_UPDATE_13-05-2025.txt', delimiter='\t')
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/dveytia/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-06 08:40:17.264582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32 and shape [948,512]
	 [[{{node Placeholder/_0}}]]
2025-07-06 08:40:17.264903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [948]
	 [[{{node Placeholder/_2}}]]
Epoch 1/4
 1/60 [..............................] - ETA: 23:19 - loss: 0.6830 - binary_accuracy: 0.7500 1/60 [..............................] - ETA: 23:34 - loss: 0.6949 - binary_accuracy: 0.5625 1/60 [..............................] - ETA: 23:36 - loss: 0.6825 - binary_accuracy: 0.7500 1/60 [..............................] - ETA: 25:29 - loss: 0.7037 - binary_accuracy: 0.5000 1/60 [..............................] - ETA: 25:28 - loss: 0.6876 - binary_accuracy: 0.6250 2/60 [>.............................] - ETA: 15:50 - loss: 0.6623 - binary_accuracy: 0.7500 2/60 [>.............................] - ETA: 15:44 - loss: 0.6829 - binary_accuracy: 0.6562 2/60 [>.............................] - ETA: 15:40 - loss: 0.6712 - binary_accuracy: 0.7188 2/60 [>.............................] - ETA: 17:08 - loss: 0.6914 - binary_accuracy: 0.7188 2/60 [>.............................] - ETA: 16:58 - loss: 0.6658 - binary_accuracy: 0.7500 3/60 [>.............................] - ETA: 15:27 - loss: 0.6532 - binary_accuracy: 0.7292 3/60 [>.............................] - ETA: 15:30 - loss: 0.6722 - binary_accuracy: 0.6667 3/60 [>.............................] - ETA: 15:17 - loss: 0.6447 - binary_accuracy: 0.7500 3/60 [>.............................] - ETA: 16:36 - loss: 0.6806 - binary_accuracy: 0.7292 3/60 [>.............................] - ETA: 16:35 - loss: 0.6575 - binary_accuracy: 0.7292 4/60 [=>............................] - ETA: 15:08 - loss: 0.6468 - binary_accuracy: 0.7188 4/60 [=>............................] - ETA: 15:14 - loss: 0.6578 - binary_accuracy: 0.6875 4/60 [=>............................] - ETA: 15:01 - loss: 0.6274 - binary_accuracy: 0.7500 4/60 [=>............................] - ETA: 16:14 - loss: 0.6744 - binary_accuracy: 0.7031 4/60 [=>............................] - ETA: 16:15 - loss: 0.6666 - binary_accuracy: 0.6875 5/60 [=>............................] - ETA: 14:50 - loss: 0.6463 - binary_accuracy: 0.7000 5/60 [=>............................] - ETA: 14:54 - loss: 0.6498 - binary_accuracy: 0.6875 5/60 [=>............................] - ETA: 14:47 - loss: 0.6038 - binary_accuracy: 0.7625 5/60 [=>............................] - ETA: 15:53 - loss: 0.6604 - binary_accuracy: 0.7125 5/60 [=>............................] - ETA: 15:55 - loss: 0.6558 - binary_accuracy: 0.6875 6/60 [==>...........................] - ETA: 14:30 - loss: 0.6652 - binary_accuracy: 0.6667 6/60 [==>...........................] - ETA: 14:37 - loss: 0.6210 - binary_accuracy: 0.7188 6/60 [==>...........................] - ETA: 14:32 - loss: 0.6048 - binary_accuracy: 0.7500 6/60 [==>...........................] - ETA: 15:35 - loss: 0.6423 - binary_accuracy: 0.7292 6/60 [==>...........................] - ETA: 15:37 - loss: 0.6340 - binary_accuracy: 0.7083 7/60 [==>...........................] - ETA: 14:14 - loss: 0.6531 - binary_accuracy: 0.6786 7/60 [==>...........................] - ETA: 14:20 - loss: 0.5953 - binary_accuracy: 0.7411 7/60 [==>...........................] - ETA: 14:17 - loss: 0.5950 - binary_accuracy: 0.7500 8/60 [===>..........................] - ETA: 13:58 - loss: 0.6458 - binary_accuracy: 0.6797 7/60 [==>...........................] - ETA: 15:18 - loss: 0.6179 - binary_accuracy: 0.7500 7/60 [==>...........................] - ETA: 15:20 - loss: 0.6123 - binary_accuracy: 0.7232 8/60 [===>..........................] - ETA: 14:01 - loss: 0.6076 - binary_accuracy: 0.7266 8/60 [===>..........................] - ETA: 14:02 - loss: 0.5820 - binary_accuracy: 0.7578 9/60 [===>..........................] - ETA: 13:41 - loss: 0.6356 - binary_accuracy: 0.6875 8/60 [===>..........................] - ETA: 15:00 - loss: 0.6256 - binary_accuracy: 0.7344 8/60 [===>..........................] - ETA: 15:02 - loss: 0.6154 - binary_accuracy: 0.7109 9/60 [===>..........................] - ETA: 13:46 - loss: 0.5861 - binary_accuracy: 0.7431 9/60 [===>..........................] - ETA: 13:44 - loss: 0.5589 - binary_accuracy: 0.770810/60 [====>.........................] - ETA: 13:25 - loss: 0.6297 - binary_accuracy: 0.687510/60 [====>.........................] - ETA: 13:30 - loss: 0.5898 - binary_accuracy: 0.7375 9/60 [===>..........................] - ETA: 14:40 - loss: 0.6627 - binary_accuracy: 0.6944 9/60 [===>..........................] - ETA: 14:44 - loss: 0.6082 - binary_accuracy: 0.715310/60 [====>.........................] - ETA: 13:29 - loss: 0.5613 - binary_accuracy: 0.762511/60 [====>.........................] - ETA: 13:10 - loss: 0.6265 - binary_accuracy: 0.687511/60 [====>.........................] - ETA: 13:14 - loss: 0.5791 - binary_accuracy: 0.744310/60 [====>.........................] - ETA: 14:22 - loss: 0.6408 - binary_accuracy: 0.712510/60 [====>.........................] - ETA: 14:26 - loss: 0.5964 - binary_accuracy: 0.718811/60 [====>.........................] - ETA: 13:13 - loss: 0.5618 - binary_accuracy: 0.750012/60 [=====>........................] - ETA: 12:53 - loss: 0.6187 - binary_accuracy: 0.687512/60 [=====>........................] - ETA: 12:59 - loss: 0.5742 - binary_accuracy: 0.744811/60 [====>.........................] - ETA: 14:04 - loss: 0.6426 - binary_accuracy: 0.704511/60 [====>.........................] - ETA: 14:08 - loss: 0.5861 - binary_accuracy: 0.721612/60 [=====>........................] - ETA: 12:56 - loss: 0.5494 - binary_accuracy: 0.755213/60 [=====>........................] - ETA: 12:36 - loss: 0.5989 - binary_accuracy: 0.706713/60 [=====>........................] - ETA: 12:43 - loss: 0.5744 - binary_accuracy: 0.740412/60 [=====>........................] - ETA: 13:46 - loss: 0.6267 - binary_accuracy: 0.718813/60 [=====>........................] - ETA: 12:40 - loss: 0.5420 - binary_accuracy: 0.750012/60 [=====>........................] - ETA: 13:50 - loss: 0.5694 - binary_accuracy: 0.734414/60 [======>.......................] - ETA: 12:20 - loss: 0.5873 - binary_accuracy: 0.714314/60 [======>.......................] - ETA: 12:26 - loss: 0.5728 - binary_accuracy: 0.736613/60 [=====>........................] - ETA: 13:28 - loss: 0.6271 - binary_accuracy: 0.711514/60 [======>.......................] - ETA: 12:24 - loss: 0.5446 - binary_accuracy: 0.732113/60 [=====>........................] - ETA: 13:31 - loss: 0.5556 - binary_accuracy: 0.735615/60 [======>.......................] - ETA: 12:04 - loss: 0.5725 - binary_accuracy: 0.725015/60 [======>.......................] - ETA: 12:10 - loss: 0.5649 - binary_accuracy: 0.737515/60 [======>.......................] - ETA: 12:08 - loss: 0.5364 - binary_accuracy: 0.729214/60 [======>.......................] - ETA: 13:11 - loss: 0.6209 - binary_accuracy: 0.714314/60 [======>.......................] - ETA: 13:14 - loss: 0.5559 - binary_accuracy: 0.723216/60 [=======>......................] - ETA: 11:48 - loss: 0.5865 - binary_accuracy: 0.710916/60 [=======>......................] - ETA: 11:54 - loss: 0.5530 - binary_accuracy: 0.746116/60 [=======>......................] - ETA: 11:52 - loss: 0.5289 - binary_accuracy: 0.726615/60 [======>.......................] - ETA: 12:53 - loss: 0.6187 - binary_accuracy: 0.708315/60 [======>.......................] - ETA: 12:56 - loss: 0.5422 - binary_accuracy: 0.733317/60 [=======>......................] - ETA: 11:33 - loss: 0.5762 - binary_accuracy: 0.713217/60 [=======>......................] - ETA: 11:37 - loss: 0.5501 - binary_accuracy: 0.746317/60 [=======>......................] - ETA: 11:36 - loss: 0.5186 - binary_accuracy: 0.735316/60 [=======>......................] - ETA: 12:35 - loss: 0.6120 - binary_accuracy: 0.707016/60 [=======>......................] - ETA: 12:38 - loss: 0.5348 - binary_accuracy: 0.730518/60 [========>.....................] - ETA: 11:16 - loss: 0.5583 - binary_accuracy: 0.729218/60 [========>.....................] - ETA: 11:21 - loss: 0.5401 - binary_accuracy: 0.750018/60 [========>.....................] - ETA: 11:19 - loss: 0.5038 - binary_accuracy: 0.736117/60 [=======>......................] - ETA: 12:18 - loss: 0.6038 - binary_accuracy: 0.705917/60 [=======>......................] - ETA: 12:21 - loss: 0.5260 - binary_accuracy: 0.727919/60 [========>.....................] - ETA: 11:00 - loss: 0.5503 - binary_accuracy: 0.733619/60 [========>.....................] - ETA: 11:05 - loss: 0.5385 - binary_accuracy: 0.743419/60 [========>.....................] - ETA: 11:03 - loss: 0.5017 - binary_accuracy: 0.733618/60 [========>.....................] - ETA: 11:59 - loss: 0.5911 - binary_accuracy: 0.711818/60 [========>.....................] - ETA: 12:02 - loss: 0.5189 - binary_accuracy: 0.736120/60 [=========>....................] - ETA: 10:44 - loss: 0.5393 - binary_accuracy: 0.734420/60 [=========>....................] - ETA: 10:48 - loss: 0.5350 - binary_accuracy: 0.737520/60 [=========>....................] - ETA: 10:47 - loss: 0.4929 - binary_accuracy: 0.737519/60 [========>.....................] - ETA: 11:40 - loss: 0.5774 - binary_accuracy: 0.723719/60 [========>.....................] - ETA: 11:42 - loss: 0.5143 - binary_accuracy: 0.740121/60 [=========>....................] - ETA: 10:28 - loss: 0.5330 - binary_accuracy: 0.735121/60 [=========>....................] - ETA: 10:32 - loss: 0.5256 - binary_accuracy: 0.738121/60 [=========>....................] - ETA: 10:30 - loss: 0.4931 - binary_accuracy: 0.735120/60 [=========>....................] - ETA: 11:22 - loss: 0.5677 - binary_accuracy: 0.721920/60 [=========>....................] - ETA: 11:24 - loss: 0.5090 - binary_accuracy: 0.746922/60 [==========>...................] - ETA: 10:12 - loss: 0.5206 - binary_accuracy: 0.741522/60 [==========>...................] - ETA: 10:16 - loss: 0.5149 - binary_accuracy: 0.738622/60 [==========>...................] - ETA: 10:14 - loss: 0.4815 - binary_accuracy: 0.744321/60 [=========>....................] - ETA: 11:05 - loss: 0.5582 - binary_accuracy: 0.723221/60 [=========>....................] - ETA: 11:07 - loss: 0.5109 - binary_accuracy: 0.747023/60 [==========>...................] - ETA: 9:55 - loss: 0.5141 - binary_accuracy: 0.7364 23/60 [==========>...................] - ETA: 9:59 - loss: 0.5123 - binary_accuracy: 0.7446 23/60 [==========>...................] - ETA: 9:59 - loss: 0.4764 - binary_accuracy: 0.7473 22/60 [==========>...................] - ETA: 10:48 - loss: 0.5492 - binary_accuracy: 0.724422/60 [==========>...................] - ETA: 10:50 - loss: 0.4971 - binary_accuracy: 0.758524/60 [===========>..................] - ETA: 9:40 - loss: 0.5071 - binary_accuracy: 0.731824/60 [===========>..................] - ETA: 9:43 - loss: 0.5103 - binary_accuracy: 0.747424/60 [===========>..................] - ETA: 9:42 - loss: 0.4684 - binary_accuracy: 0.752623/60 [==========>...................] - ETA: 10:31 - loss: 0.5364 - binary_accuracy: 0.731023/60 [==========>...................] - ETA: 10:33 - loss: 0.4925 - binary_accuracy: 0.760925/60 [===========>..................] - ETA: 9:24 - loss: 0.4995 - binary_accuracy: 0.732525/60 [===========>..................] - ETA: 9:26 - loss: 0.4993 - binary_accuracy: 0.755025/60 [===========>..................] - ETA: 9:26 - loss: 0.4658 - binary_accuracy: 0.752524/60 [===========>..................] - ETA: 10:15 - loss: 0.5305 - binary_accuracy: 0.739626/60 [============>.................] - ETA: 9:08 - loss: 0.4904 - binary_accuracy: 0.735624/60 [===========>..................] - ETA: 10:17 - loss: 0.4902 - binary_accuracy: 0.760426/60 [============>.................] - ETA: 9:10 - loss: 0.4906 - binary_accuracy: 0.757226/60 [============>.................] - ETA: 9:10 - loss: 0.4652 - binary_accuracy: 0.752427/60 [============>.................] - ETA: 8:52 - loss: 0.4792 - binary_accuracy: 0.743125/60 [===========>..................] - ETA: 9:58 - loss: 0.5236 - binary_accuracy: 0.7450 25/60 [===========>..................] - ETA: 10:00 - loss: 0.4816 - binary_accuracy: 0.762527/60 [============>.................] - ETA: 8:54 - loss: 0.4868 - binary_accuracy: 0.756927/60 [============>.................] - ETA: 8:54 - loss: 0.4649 - binary_accuracy: 0.756928/60 [=============>................] - ETA: 8:36 - loss: 0.4766 - binary_accuracy: 0.745526/60 [============>.................] - ETA: 9:41 - loss: 0.5103 - binary_accuracy: 0.754828/60 [=============>................] - ETA: 8:38 - loss: 0.4873 - binary_accuracy: 0.756726/60 [============>.................] - ETA: 9:43 - loss: 0.4829 - binary_accuracy: 0.7596 28/60 [=============>................] - ETA: 8:38 - loss: 0.4650 - binary_accuracy: 0.758929/60 [=============>................] - ETA: 8:19 - loss: 0.4705 - binary_accuracy: 0.752227/60 [============>.................] - ETA: 9:24 - loss: 0.5041 - binary_accuracy: 0.754629/60 [=============>................] - ETA: 8:22 - loss: 0.4824 - binary_accuracy: 0.760827/60 [============>.................] - ETA: 9:26 - loss: 0.4817 - binary_accuracy: 0.761629/60 [=============>................] - ETA: 8:22 - loss: 0.4652 - binary_accuracy: 0.756530/60 [==============>...............] - ETA: 8:04 - loss: 0.4649 - binary_accuracy: 0.756328/60 [=============>................] - ETA: 9:07 - loss: 0.5053 - binary_accuracy: 0.750030/60 [==============>...............] - ETA: 8:06 - loss: 0.4821 - binary_accuracy: 0.760428/60 [=============>................] - ETA: 9:09 - loss: 0.4714 - binary_accuracy: 0.767930/60 [==============>...............] - ETA: 8:06 - loss: 0.4645 - binary_accuracy: 0.754231/60 [==============>...............] - ETA: 7:47 - loss: 0.4571 - binary_accuracy: 0.762131/60 [==============>...............] - ETA: 7:50 - loss: 0.4780 - binary_accuracy: 0.764129/60 [=============>................] - ETA: 8:50 - loss: 0.4997 - binary_accuracy: 0.752229/60 [=============>................] - ETA: 8:52 - loss: 0.4647 - binary_accuracy: 0.771631/60 [==============>...............] - ETA: 7:49 - loss: 0.4645 - binary_accuracy: 0.756032/60 [===============>..............] - ETA: 7:32 - loss: 0.4512 - binary_accuracy: 0.765632/60 [===============>..............] - ETA: 7:33 - loss: 0.4758 - binary_accuracy: 0.767630/60 [==============>...............] - ETA: 8:33 - loss: 0.4990 - binary_accuracy: 0.750030/60 [==============>...............] - ETA: 8:34 - loss: 0.4615 - binary_accuracy: 0.772932/60 [===============>..............] - ETA: 7:33 - loss: 0.4604 - binary_accuracy: 0.757833/60 [===============>..............] - ETA: 7:16 - loss: 0.4513 - binary_accuracy: 0.765233/60 [===============>..............] - ETA: 7:17 - loss: 0.4702 - binary_accuracy: 0.772731/60 [==============>...............] - ETA: 8:15 - loss: 0.4982 - binary_accuracy: 0.754031/60 [==============>...............] - ETA: 8:17 - loss: 0.4575 - binary_accuracy: 0.776233/60 [===============>..............] - ETA: 7:17 - loss: 0.4625 - binary_accuracy: 0.757634/60 [================>.............] - ETA: 6:59 - loss: 0.4488 - binary_accuracy: 0.768434/60 [================>.............] - ETA: 7:01 - loss: 0.4649 - binary_accuracy: 0.777632/60 [===============>..............] - ETA: 7:58 - loss: 0.4915 - binary_accuracy: 0.757834/60 [================>.............] - ETA: 7:01 - loss: 0.4568 - binary_accuracy: 0.761032/60 [===============>..............] - ETA: 7:59 - loss: 0.4570 - binary_accuracy: 0.777335/60 [================>.............] - ETA: 6:43 - loss: 0.4409 - binary_accuracy: 0.773235/60 [================>.............] - ETA: 6:44 - loss: 0.4682 - binary_accuracy: 0.773235/60 [================>.............] - ETA: 6:45 - loss: 0.4598 - binary_accuracy: 0.757133/60 [===============>..............] - ETA: 7:41 - loss: 0.4911 - binary_accuracy: 0.757633/60 [===============>..............] - ETA: 7:42 - loss: 0.4525 - binary_accuracy: 0.780336/60 [=================>............] - ETA: 6:27 - loss: 0.4395 - binary_accuracy: 0.772636/60 [=================>............] - ETA: 6:28 - loss: 0.4637 - binary_accuracy: 0.777836/60 [=================>............] - ETA: 6:28 - loss: 0.4634 - binary_accuracy: 0.751734/60 [================>.............] - ETA: 7:24 - loss: 0.4901 - binary_accuracy: 0.757434/60 [================>.............] - ETA: 7:25 - loss: 0.4501 - binary_accuracy: 0.781237/60 [=================>............] - ETA: 6:11 - loss: 0.4339 - binary_accuracy: 0.775337/60 [=================>............] - ETA: 6:12 - loss: 0.4623 - binary_accuracy: 0.778737/60 [=================>............] - ETA: 6:12 - loss: 0.4638 - binary_accuracy: 0.744935/60 [================>.............] - ETA: 7:07 - loss: 0.4845 - binary_accuracy: 0.762535/60 [================>.............] - ETA: 7:08 - loss: 0.4449 - binary_accuracy: 0.783938/60 [==================>...........] - ETA: 5:55 - loss: 0.4413 - binary_accuracy: 0.773038/60 [==================>...........] - ETA: 5:56 - loss: 0.4558 - binary_accuracy: 0.782938/60 [==================>...........] - ETA: 5:56 - loss: 0.4596 - binary_accuracy: 0.746736/60 [=================>............] - ETA: 6:50 - loss: 0.4779 - binary_accuracy: 0.767436/60 [=================>............] - ETA: 6:51 - loss: 0.4467 - binary_accuracy: 0.784739/60 [==================>...........] - ETA: 5:39 - loss: 0.4395 - binary_accuracy: 0.774039/60 [==================>...........] - ETA: 5:39 - loss: 0.4523 - binary_accuracy: 0.783739/60 [==================>...........] - ETA: 5:39 - loss: 0.4563 - binary_accuracy: 0.746837/60 [=================>............] - ETA: 6:33 - loss: 0.4708 - binary_accuracy: 0.772037/60 [=================>............] - ETA: 6:34 - loss: 0.4456 - binary_accuracy: 0.785540/60 [===================>..........] - ETA: 5:23 - loss: 0.4356 - binary_accuracy: 0.776640/60 [===================>..........] - ETA: 5:23 - loss: 0.4437 - binary_accuracy: 0.7875