=======================TASK PROLOG================================
Job 7516970 submitted on cluster spiritx from spiritx1.ipsl.fr
Job 7516970 submitted by dveytia with account lmd
Job 7516970 is running with 1 nodes and 31 cores on spiritx64-9
Job 7516970 memory requirements are 122880 MB per node
Job 7516970 starting at 2025/07/01 15:24:04
==================================================================
#!/bin/ksh -vx
#SBATCH --verbose
#SBATCH --output="%x.out_%j"
#SBATCH --nodes=1
#SBATCH --ntasks=10
#SBATCH --mem=120GB
#SBATCH --time=168:00:00
### on rentre dans le repertoire de run


cd /home/dveytia/IPython_Notebooks/Product_1/analyses/06_binary_outcome_quantitative

+ cd /home/dveytia/IPython_Notebooks/Product_1/analyses/06_binary_outcome_quantitative
mpiexec -n 5 python 06_binary_outcome_quantitative_prediction.py+ mpiexec -n 5 python 06_binary_outcome_quantitative_prediction.py
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
3.8.18 (default, Sep 11 2023, 13:20:55) 
[GCC 11.2.0]
2025-07-01 15:24:06.955664: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-01 15:24:06.955654: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-01 15:24:06.955677: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-01 15:24:06.955664: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-01 15:24:06.955664: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-01 15:24:07.214890: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-01 15:24:07.214881: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-01 15:24:07.214899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-01 15:24:07.214890: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-01 15:24:07.214871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-01 15:24:08.332966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-01 15:24:08.332965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-01 15:24:08.332968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-01 15:24:08.332967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-01 15:24:08.332965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Dataset has been re-formatted and is ready
Dataset has been re-formatted and is ready
Dataset has been re-formatted and is ready
Dataset has been re-formatted and is ready
Dataset has been re-formatted and is ready
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}', 'F1': 0.8867290404534723}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}'}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}', 'F1': 0.8867290404534723}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}'}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}', 'F1': 0.8867290404534723}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}'}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}', 'F1': 0.8867290404534723}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}'}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}', 'F1': 0.8867290404534723}
{'batch_size': 16, 'weight_decay': 0.0, 'learning_rate': 5e-05, 'num_epochs': 4, 'class_weight': '{0: 1, 1: 0.40332640332640335}'}
